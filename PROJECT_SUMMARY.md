# Generative Resume and Cover Letter Assistant
## Project Summary & Technical Documentation

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [System Architecture](#system-architecture)
3. [Backend Architecture](#backend-architecture)
4. [Frontend Architecture](#frontend-architecture)
5. [Core Functionalities](#core-functionalities)
6. [Technical Stack](#technical-stack)
7. [Workflow & Pipeline](#workflow--pipeline)
8. [Key Features](#key-features)

---

## ğŸ¯ Project Overview

**Generative Resume and Cover Letter Assistant** is an intelligent AI-powered system that analyzes job descriptions and candidate profiles to generate **grounded, evidence-based resume bullets and tailored cover letters**. The system ensures all generated content is verifiable by linking it to specific evidence chunks from the candidate's profile, preventing hallucinations and maintaining authenticity.

### Core Value Proposition
- **Grounded Generation**: All outputs are backed by evidence from the candidate's profile
- **Multi-Method Retrieval**: Combines TF-IDF, BM25, and semantic embeddings for robust matching
- **Transparent Evidence**: Provides detailed evidence maps showing how requirements match profile chunks
- **Configurable Pipeline**: Flexible retrieval and generation options for different use cases
- **Modern UI**: Clean, responsive interface with real-time feedback

---

## ğŸ—ï¸ System Architecture

The system follows a **client-server architecture** with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js)                        â”‚
â”‚  - React 19 + TypeScript                                     â”‚
â”‚  - shadcn/ui components                                      â”‚
â”‚  - PDF upload & text extraction                              â”‚
â”‚  - Real-time result visualization                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/REST API
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Backend (FastAPI)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Orchestrator (Main Pipeline)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Retrievalâ”‚  â”‚ Matching â”‚  â”‚ Evidence â”‚  â”‚Generation â”‚ â”‚
â”‚  â”‚  Engine  â”‚  â”‚  Engine  â”‚  â”‚  Builder â”‚  â”‚  Engine   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ TF-IDF   â”‚  â”‚   BM25   â”‚  â”‚Embeddingsâ”‚              â”‚
â”‚  â”‚  Index   â”‚  â”‚  Index   â”‚  â”‚  Index   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   LLM    â”‚  â”‚   LLM    â”‚  â”‚   LLM    â”‚              â”‚
â”‚  â”‚Classifierâ”‚  â”‚ Generatorâ”‚  â”‚  Editor  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Backend Architecture

### **Technology Stack**
- **Framework**: FastAPI (Python 3.10+)
- **LLM Provider**: OpenAI (GPT-4o-mini, text-embedding-3-small)
- **NLP Libraries**: Custom implementations for TF-IDF, BM25
- **Data Processing**: NumPy, regex, JSON
- **PDF Processing**: pdfplumber (for Streamlit interface)

### **Core Modules**

#### 1. **Orchestrator (`orchestrator.py`)**
The main pipeline coordinator that orchestrates the entire workflow:
- Coordinates all pipeline stages
- Manages configuration and environment setup
- Handles adaptive weight calculation for hybrid ranking
- Exports results in multiple formats (JSON, Markdown, ZIP)

#### 2. **Retrieval System**
Three complementary retrieval methods:

**a) TF-IDF Index (`retrieval_tfidf.py`)**
- Classic keyword-based retrieval
- Term frequency-inverse document frequency weighting
- Best for exact keyword matching

**b) BM25 Index (`retrieval_bm25.py`)**
- Probabilistic ranking function
- Strong baseline for textual relevance
- Handles term saturation better than TF-IDF

**c) Embedding Index (`retrieval_embed.py`)**
- Semantic similarity using OpenAI embeddings
- Captures meaning beyond keywords
- Requires API calls but provides deeper understanding

#### 3. **Profile Processing (`core/chunking.py`)**
- **Section Detection**: Automatically identifies resume sections (Summary, Experience, Projects, Skills, Education)
- **Intelligent Chunking**: Splits profile into overlapping chunks (default: 1200 chars, 200 char overlap)
- **Tokenization**: Preprocesses text with stopword removal
- **Chunk Metadata**: Each chunk includes section, text, tokens, and unique ID

#### 4. **Job Description Parsing**

**a) Rule-Based Parser (`agents/jd_parser_rules.py`)**
- Extracts must-have skills, nice-to-have skills, responsibilities, keywords
- Uses skill taxonomy for normalization
- Fast and deterministic

**b) LLM-Based Classifier (`agents/jd_classifier_llm.py`)**
- Optional LLM-powered refinement
- Better understanding of context and implicit requirements
- More accurate skill extraction from complex descriptions

#### 5. **Hybrid Ranking System (`core/ranker.py`)**
- **Multi-Method Fusion**: Combines TF-IDF, BM25, and embedding scores
- **Adaptive Weights**: Automatically adjusts weights based on enabled methods
- **Normalization**: Min-max normalization for fair score combination
- **Match Thresholding**: Configurable threshold for requirement matching
- **Score Calculation**:
  - Final score = (w_tfidf Ã— score_tfidf) + (w_bm25 Ã— score_bm25) + (w_embed Ã— score_embed)
  - Default weights: BM25 (45%), TF-IDF (35%), Embeddings (20%)

#### 6. **Evidence Map Builder (`core/evidence.py`)**
- Links requirements to supporting profile chunks
- Extracts skills found in chunks using taxonomy
- Provides detailed scoring breakdown (final, TF-IDF, BM25 scores)
- Creates traceable evidence chain for each requirement

#### 7. **Generation System**

**a) LLM Generator (`agents/generator_llm.py`)**
- Generates resume bullets and cover letter
- Uses structured JSON prompts with few-shot examples
- Ensures all outputs reference evidence chunks
- Temperature: 0.2 (low for consistency)

**b) LLM Editor (`agents/editor_llm.py`)**
- Optional post-generation refinement
- Fixes validation issues while maintaining grounding
- Improves style and coherence

#### 8. **Validation & Grounding (`core/validators.py`)**
- **Content Validation**: Checks bullet length, evidence references, skill usage
- **Grounding Enforcement**: Ensures all claims are backed by evidence
- **Warning System**: Identifies potential issues without blocking generation
- **Taxonomy Verification**: Validates skills against known taxonomy

#### 9. **Export System (`core/export.py`)**
- JSON export for programmatic access
- Markdown export for human-readable output
- ZIP package containing all exports

### **API Endpoints**

#### `POST /run`
Main pipeline endpoint that processes job description and profile.

**Request Body:**
```json
{
  "job_description": "Full job description text...",
  "profile_text": "Candidate profile/resume text...",
  "company_name": "Optional company name",
  "role_title": "Optional role title",
  "use_tfidf": true,
  "use_bm25": true,
  "use_embeddings": false,
  "use_llm_jd_classifier": false,
  "use_llm_editor": true
}
```

**Response:**
```json
{
  "jd": {
    "company_name": "...",
    "role_title": "...",
    "must_have_skills": [...],
    "nice_to_have_skills": [...],
    "responsibilities": [...],
    "keywords": [...]
  },
  "match_report": {
    "match_score_overall": 85,
    "match_score_must": 90,
    "match_score_nice": 80,
    "matched_requirements": [...],
    "missing_requirements": [...]
  },
  "evidence_map": {...},
  "generation": {
    "resume_bullets": [...],
    "cover_letter": {...},
    "warnings": [...]
  },
  "validation": {
    "ok": true,
    "warnings": [...]
  }
}
```

#### `GET /health`
Health check endpoint for monitoring.

---

## ğŸ¨ Frontend Architecture

### **Technology Stack**
- **Framework**: Next.js 16 (React 19)
- **Language**: TypeScript
- **UI Library**: shadcn/ui (Radix UI primitives)
- **Styling**: Tailwind CSS 4
- **Icons**: Lucide React
- **PDF Processing**: unpdf (serverless-compatible)

### **Key Components**

#### 1. **Request Form (`request-form.tsx`)**
- Job description input (textarea)
- Profile/resume input with **PDF upload support**
- Drag-and-drop PDF upload
- Company and role fields (optional)
- Configurable retrieval options (TF-IDF, BM25, Embeddings)
- Configurable generation options (LLM JD Classifier, LLM Editor)
- Sample data loader for quick testing

#### 2. **Match Summary (`match-summary.tsx`)**
- **Match Score Visualization**: 
  - Overall, Must-have, Nice-to-have scores
  - Color-coded progress bars (red <50%, amber 50-74%, green â‰¥75%)
  - Percentage badges
- **Skills Display**:
  - Must-have skills with count badges
  - Nice-to-have skills with accent colors
  - Responsibilities and keywords
- **Matched/Missing Requirements**: Visual badges

#### 3. **Generation Results (`generation-results.tsx`)**
- **Resume Bullets Section**:
  - Each bullet with skills used
  - Evidence chunk references
  - Item count badge
- **Cover Letter Section**:
  - Scrollable text area
  - Evidence chunk references
  - "Grounded" badge indicator
- **Validation Status**: OK/Issues badge
- **Warnings Display**: Alert component for validation warnings

#### 4. **Evidence Panel (`evidence-panel.tsx`)**
- **Fixed-height scrollable card** (matches Outputs card height)
- **Evidence Map Display**:
  - Requirements sorted by score
  - Matched/Missing badges
  - Score badges
  - Supporting chunks with:
    - Section labels
    - Score breakdowns (final, TF-IDF, BM25)
    - Chunk text (line-clamped)
    - Skills found in chunks
- **Footer**: Information about evidence derivation

### **PDF Upload Feature**

#### API Route: `/api/extract-pdf`
- Serverless function for PDF text extraction
- Uses `unpdf` library (serverless-compatible)
- Validates file type and size (10MB limit)
- Cleans extracted text (normalizes whitespace, fixes layout)
- Returns extracted text as JSON

#### Frontend Integration:
- Upload button with loading states
- Drag-and-drop support
- Real-time extraction feedback
- Automatic form population
- Character/line count display

---

## ğŸ”„ Workflow & Pipeline

### **Complete Pipeline Flow**

```
1. INPUT PROCESSING
   â”œâ”€ Job Description Parsing
   â”‚  â”œâ”€ Extract company/role (regex)
   â”‚  â”œâ”€ Rule-based skill extraction
   â”‚  â””â”€ Optional: LLM-based refinement
   â”‚
   â””â”€ Profile Processing
      â”œâ”€ Section detection (Summary, Experience, etc.)
      â”œâ”€ Chunking (1200 chars, 200 overlap)
      â””â”€ Tokenization & preprocessing

2. RETRIEVAL PHASE
   â”œâ”€ For each requirement:
   â”‚  â”œâ”€ TF-IDF retrieval (if enabled)
   â”‚  â”œâ”€ BM25 retrieval (if enabled)
   â”‚  â””â”€ Embedding retrieval (if enabled)
   â”‚
   â””â”€ Hybrid ranking
      â”œâ”€ Score normalization (min-max)
      â”œâ”€ Weighted combination
      â””â”€ Top-K chunk selection

3. MATCHING & EVIDENCE
   â”œâ”€ Requirement matching (threshold-based)
   â”œâ”€ Evidence map construction
   â”‚  â”œâ”€ Link requirements to chunks
   â”‚  â”œâ”€ Extract skills from chunks
   â”‚  â””â”€ Calculate match scores
   â”‚
   â””â”€ Match report generation
      â”œâ”€ Overall score
      â”œâ”€ Must-have score
      â”œâ”€ Nice-to-have score
      â””â”€ Matched/missing lists

4. GENERATION PHASE
   â”œâ”€ LLM Generation
   â”‚  â”œâ”€ Resume bullets (evidence-grounded)
   â”‚  â”œâ”€ Cover letter (tailored to JD)
   â”‚  â””â”€ Evidence chunk references
   â”‚
   â”œâ”€ Validation
   â”‚  â”œâ”€ Check bullet length
   â”‚  â”œâ”€ Verify evidence references
   â”‚  â””â”€ Validate skill usage
   â”‚
   â””â”€ Optional: LLM Editing
      â”œâ”€ Fix validation issues
      â”œâ”€ Improve style
      â””â”€ Maintain grounding

5. OUTPUT & EXPORT
   â”œâ”€ JSON export (full data)
   â”œâ”€ Markdown export (human-readable)
   â””â”€ ZIP package (all exports)
```

### **Adaptive Configuration**

The system adapts to enabled retrieval methods:
- **Single method**: Lower threshold (0.30 max) for more lenient matching
- **Multiple methods**: Uses configured threshold (default 0.62)
- **Weight normalization**: Automatically normalizes weights when methods are disabled

---

## âœ¨ Key Features

### **1. Multi-Method Retrieval**
- **TF-IDF**: Fast keyword matching
- **BM25**: Better term saturation handling
- **Embeddings**: Semantic understanding
- **Hybrid Fusion**: Best of all methods

### **2. Evidence-Based Generation**
- All resume bullets reference specific profile chunks
- Cover letter grounded in evidence
- Transparent evidence map for verification
- Prevents hallucinations

### **3. Intelligent Profile Processing**
- Automatic section detection
- Smart chunking with overlap
- Skill extraction from chunks
- Taxonomy-based skill normalization

### **4. Flexible Configuration**
- Toggle retrieval methods on/off
- Optional LLM-based JD classification
- Optional LLM-based editing
- Adaptive thresholds and weights

### **5. Comprehensive Validation**
- Content validation (length, format)
- Grounding verification
- Skill taxonomy checking
- Warning system (non-blocking)

### **6. Modern User Interface**
- Clean, responsive design
- Real-time feedback
- PDF upload with drag-and-drop
- Visual score indicators
- Scrollable evidence maps
- Color-coded progress bars

### **7. Export Capabilities**
- JSON for programmatic access
- Markdown for human reading
- ZIP packages for distribution

---

## ğŸ› ï¸ Technical Stack Summary

### **Backend**
- Python 3.10+
- FastAPI (REST API)
- OpenAI API (GPT-4o-mini, text-embedding-3-small)
- NumPy (vector operations)
- pdfplumber (PDF extraction for Streamlit)
- Pydantic (data validation)

### **Frontend**
- Next.js 16
- React 19
- TypeScript
- Tailwind CSS 4
- shadcn/ui (Radix UI)
- unpdf (PDF extraction)
- Lucide React (icons)

### **Data Formats**
- JSON (API communication, exports)
- Markdown (human-readable exports)
- YAML (skill taxonomy, configuration)

---

## ğŸ“Š Performance Characteristics

- **Retrieval Speed**: TF-IDF/BM25 are fast (milliseconds), embeddings require API calls
- **Generation Time**: ~5-15 seconds depending on LLM model and content length
- **Scalability**: Stateless API design allows horizontal scaling
- **Memory**: Efficient chunking keeps memory usage reasonable

---

## ğŸ”’ Quality Assurance

- **Grounded Generation**: All outputs linked to evidence
- **Validation System**: Multi-layer validation prevents errors
- **Error Handling**: Graceful degradation when methods fail
- **Type Safety**: TypeScript on frontend, Pydantic on backend

---

## ğŸš€ Future Enhancements

Potential improvements:
- Caching for repeated queries
- Batch processing for multiple JDs
- Custom skill taxonomy upload
- Export to DOCX/PDF formats
- Multi-language support
- Advanced analytics dashboard

---

## ğŸ“ Conclusion

The **Generative Resume and Cover Letter Assistant** demonstrates a production-ready approach to AI-powered content generation with strong emphasis on:
- **Transparency**: Clear evidence mapping
- **Reliability**: Multi-method retrieval and validation
- **Flexibility**: Configurable pipeline
- **User Experience**: Modern, intuitive interface

The system successfully combines traditional NLP techniques (TF-IDF, BM25) with modern AI (embeddings, LLMs) to create a robust, grounded generation pipeline.

---

*Document generated for presentation purposes*
*Last updated: 2024*

